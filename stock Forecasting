            #using machine learning models to forecast stock prices
import quandl
import numpy as np
from sklearn.linear_model import LinearRegression
from sklearn.svm import SVR             #support vector regression algorithm
from sklearn.model_selection import train_test_split     #method being used to split and train data

#getting the stock data
df = quandl.get("WIKI/TSLA")   #df = dataframe
print(df.head())                #Take a look at the data

   #we only care about the adjusted close, so lets isolate it and re-print
df = df[['Adj. Close']]          #in this case, Adj. Close is our Independant Variable
print(df.head())

#Now, lets create a variable to predict out into the future
forecast = 7                         #how many 'n' days out 
                #Creating another column using the shift method so we have a Dependant Variable
df['Prediction'] = df[['Adj. Close']].shift(-forecast)         #Because we want to shift our data up 'n' days
print(df.tail())                            #At this point, the program does not tell us the prediction value of a future date yet

#########################################################################################################

#Now lets create our independant dataset X
    #First, we convert the df into a np array
X = np.array(df.drop(columns=['Prediction']))
      #Now remove the last 'n' rows
X = X[:-forecast]
print(X)

##########################################################################################################

#Now create a Dependant Variable dataset Y
#Convert datframe again to array
Y = np.array(df['Prediction'])        #This will still show all values including NaN's, more manipulation will have to be done 
       #Now get all Y values except last 'n' days (same as before with X)
Y = Y[:-forecast]
print(Y)

#########################################################################################################

#Now, lets split the model into 80% training and 20% testing, we use train_test_split
x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size= 0.2)

#Now create and train the Support Vector Machine which is also the regressor
svr_rbf = SVR(kernel= 'rbf', C= 1e3, gamma = 0.1)                #rbf = radio basis function kernel
     #Now train the model
svr_rbf.fit(x_train, y_train)

##########################################################################################################

#Testing Model: Score returns the coefficient of determination R^2 of the prediction, Top score is 1.0
svm_confidence = svr_rbf.score(x_test, y_test)
print("svm confidence: ", svm_confidence)           

  #Now create and train linear regression model
Lr = LinearRegression()
Lr.fit(x_test, y_test)            #fit is another way of saying training


#Testing Model: Score returns the coefficient of determination R^2 of the prediction, Top score is 1.0,  copied upper code
Lr_confidence = Lr.score(x_test, y_test)
print("Lr confidence: ", Lr_confidence)  

########################################################################################################
     #FORECASTING!!! Get rid of the NaN's

#Now set X_forecast as the last 7 or 'n' of the original datasetfrom the Adj. Close column 
X_forecast = np.array(df.drop(columns= ['Prediction']))[-forecast:]
print(X_forecast)

#Print Linear Regression Model predictions for the next 'n' days
Lr_Prediction = Lr.predict(X_forecast)
print(Lr_Prediction)


#Print Support Vector Regresor(SVR) Model predictions for the next 'n' days
svm_Prediction = svr_rbf.predict(X_forecast)



###
print(svm_Prediction)

